{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93f040af",
   "metadata": {},
   "source": [
    "# Some notes and references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f8b34",
   "metadata": {},
   "source": [
    "Ampligraph uses a skip gram w2v model for its embeddings\n",
    "(good explanation of skip gram - https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-skip-gram.html and this - https://towardsdatascience.com/skip-gram-nlp-context-words-prediction-algorithm-5bbf34f84e0c and this - https://towardsdatascience.com/nlp-101-word2vec-skip-gram-and-cbow-93512ee24314)\n",
    "\n",
    "w2v - https://medium.datadriveninvestor.com/word2vec-skip-gram-model-explained-383fa6ddc4ae\n",
    "\n",
    "Ampligraph blog - https://medium.com/featurepreneur/ampligraph-what-is-it-8b243800818c\n",
    "\n",
    "Tutorials from https://github.com/Accenture/AmpliGraph/blob/master/docs/tutorials/AmpliGraphBasicsTutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd270c22",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4944fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version #should be 3.7 or lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b442117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"tensorflow>=1.15.2,<2.0\" #no need to run this every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bade81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensorflow.__version__) #should be 1.15 or lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3596d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ampligraph #no need to run this every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb53da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ampligraph\n",
    "ampligraph.__version__\n",
    "#should be '1.4.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d6a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185df848",
   "metadata": {},
   "source": [
    "# Import triples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c2f950",
   "metadata": {},
   "source": [
    "These were generated from SNOMED_CT instance on CKG using terms from the pain lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879b992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples = pd.read_csv(\"all_parent_child_for_kge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d37076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3507525",
   "metadata": {},
   "source": [
    "Note: burn seems irrelevant but it has been picked up in order to capture 'burning pain'. It will be of use later on\n",
    "because some of the gold standard annotations (sentences from CRIS) also pick up burn like burn injury or \n",
    "burning things but their label in the classification will be 0 because it is not related to pain\n",
    "so leave it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de7579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples = df_triples.drop(columns='Unnamed: 0')\n",
    "df_triples.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9995ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common text preprocessing\n",
    "text = \"   This is a message to be cleaned. 92. It may involve some things like: *+ {[<br>]}, ?, :, ''  adjacent spaces and tabs     .  \"\n",
    "\n",
    "#convert to lowercase and remove punctuations and characters and then strip\n",
    "def preprocess(text):\n",
    "    text = text.lower() #lowercase text\n",
    "    text=text.strip()  #get rid of leading/trailing whitespace \n",
    "    #text=re.compile('<.*?>').sub('', text) #Remove HTML tags/markups\n",
    "    #text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  #Replace punctuation with space. Careful since punctuation can sometime be useful\n",
    "    text = re.sub('\\s+', ' ', text)  #Remove extra space and tabs\n",
    "    #text = re.sub(r'\\[[0-9]*\\]',' ',text) #[0-9] matches any digit (0 to 10000...)\n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    #text = re.sub(r'\\d',' ',text) #matches any digit from 0 to 100000..., \\D matches non-digits\n",
    "    text = re.sub(r'\\s+',' ',text) #\\s matches any whitespace, \\s+ matches multiple whitespace, \\S matches non-whitespace \n",
    "    \n",
    "    return text\n",
    "\n",
    "text=preprocess(text)\n",
    "print(text)  #text is a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f0891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples[\"subject\"] = df_triples[\"subject\"].apply(lambda x: preprocess(x)) \n",
    "df_triples[\"predicate\"] = df_triples[\"predicate\"].apply(lambda x: preprocess(x)) \n",
    "df_triples[\"object\"] = df_triples[\"object\"].apply(lambda x: preprocess(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3792aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples.describe() #top does not mean the top triple, it is the top for each category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140950b0",
   "metadata": {},
   "source": [
    "# Variation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2658d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the dataframe of triples to a list\n",
    "\n",
    "triples = df_triples.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is type and length\n",
    "\n",
    "print('type is: ', type(triples))\n",
    "print('length is: ', len(triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDuplicates(triples):\n",
    "     \n",
    "    return [t for t in (set(tuple(i) for i in triples))]\n",
    "         \n",
    "\n",
    "triples = removeDuplicates(triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6911c67f",
   "metadata": {},
   "source": [
    "Defining the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcad31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import train_test_split_no_unseen \n",
    "\n",
    "n = round((len(triples))*0.20) #get 20% of the data as test set\n",
    "\n",
    "X_train, X_valid = train_test_split_no_unseen(np.array(triples), test_size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092abb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set size: ', X_train.shape)\n",
    "print('Test set size: ', X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd9b655",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf61f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.latent_features import ComplEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e15fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can instantiate the model:\n",
    "\n",
    "model = ComplEx(batches_count=100, \n",
    "                seed=555, \n",
    "                epochs=10, \n",
    "                k=150, \n",
    "                eta=10,\n",
    "                optimizer='adam', \n",
    "                optimizer_params={'lr':1e-3},\n",
    "                loss='multiclass_nll', \n",
    "                regularizer='LP', \n",
    "                regularizer_params={'p':3, 'lambda':1e-5}, \n",
    "                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d6cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "model.fit(X_train, early_stopping = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d011c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the model is fit\n",
    "\n",
    "if model.is_fitted:\n",
    "    print('The model is fit!')\n",
    "else:\n",
    "    print('The model is not fit! Did you skip a step?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609874c5",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c294f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are filtered because they are the true triples. negatives ones are the corrput ones generated by the algorithm and are false combinations of triples\n",
    "\n",
    "filter_triples = np.concatenate((X_train, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f639c",
   "metadata": {},
   "source": [
    "arguments: \n",
    "\n",
    "X - the data to evaluate on. We're going to use our test set to evaluate.\n",
    "\n",
    "model - the model we previously trained.\n",
    "\n",
    "filter_triples - will filter out the false negatives generated by the corruption strategy.\n",
    "\n",
    "use_default_protocol - specifies whether to use the default corruption protocol. If True, then subj and obj are corrupted separately during evaluation.\n",
    "\n",
    "verbose - will give some nice log statements. Let's leave it on for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import evaluate_performance\n",
    "\n",
    "ranks = evaluate_performance(X_valid,\n",
    "                             model=model, \n",
    "                             filter_triples=filter_triples,\n",
    "                             use_default_protocol=True,\n",
    "                             verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467a3c38",
   "metadata": {},
   "source": [
    "The ranks returned by the evaluate_performance function indicate the rank at which the test set triple was found when performing link prediction using the model.\n",
    "\n",
    "For example, given the triple:\n",
    "\n",
    "<House Stark of Winterfell, IN_REGION The North>\n",
    "\n",
    "The model returns a rank of 7. This tells us that while it's not the highest likelihood true statement (which would be given a rank 1), it's pretty likely.\n",
    "\n",
    "\n",
    "Metrics\n",
    "\n",
    "Let's compute some evaluate metrics and print them out.\n",
    "\n",
    "We're going to use the mrr_score (mean reciprocal rank) and hits_at_n_score functions.\n",
    "\n",
    "mrr_score: The function computes the mean of the reciprocal of elements of a vector of rankings ranks. hits_at_n_score: The function computes how many elements of a vector of rankings ranks make it to the top n positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d24037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import mr_score, mrr_score, hits_at_n_score\n",
    "\n",
    "mrr = mrr_score(ranks)\n",
    "print(\"MRR: %.2f\" % (mrr))\n",
    "\n",
    "hits_10 = hits_at_n_score(ranks, n=10)\n",
    "print(\"Hits@10: %.5f\" % (hits_10))\n",
    "hits_3 = hits_at_n_score(ranks, n=3)\n",
    "print(\"Hits@3: %.5f\" % (hits_3))\n",
    "hits_1 = hits_at_n_score(ranks, n=1)\n",
    "print(\"Hits@1: %.5f\" % (hits_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081a3ab",
   "metadata": {},
   "source": [
    "Saving and restoring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d6234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.latent_features import save_model, restore_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c39e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'models/complex_model_mar23_variation1.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a4e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = restore_model('models/complex_model_mar23_variation1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e1bba",
   "metadata": {},
   "source": [
    "Repeat for TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.latent_features import TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde507b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransE(batches_count=100, \n",
    "               seed=555, \n",
    "               epochs=10, \n",
    "               k=150, \n",
    "               loss='pairwise',\n",
    "               loss_params={'margin':5},\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0883ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "model.fit(X_train, early_stopping = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d56208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the model is fit\n",
    "\n",
    "if model.is_fitted:\n",
    "    print('The model is fit!')\n",
    "else:\n",
    "    print('The model is not fit! Did you skip a step?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import evaluate_performance\n",
    "\n",
    "ranks = evaluate_performance(X_valid,\n",
    "                             model=model, \n",
    "                             filter_triples=filter_triples,\n",
    "                             use_default_protocol=True,\n",
    "                             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200a41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import mr_score, mrr_score, hits_at_n_score\n",
    "\n",
    "mrr = mrr_score(ranks)\n",
    "print(\"MRR: %.2f\" % (mrr))\n",
    "\n",
    "hits_10 = hits_at_n_score(ranks, n=10)\n",
    "print(\"Hits@10: %.5f\" % (hits_10))\n",
    "hits_3 = hits_at_n_score(ranks, n=3)\n",
    "print(\"Hits@3: %.5f\" % (hits_3))\n",
    "hits_1 = hits_at_n_score(ranks, n=1)\n",
    "print(\"Hits@1: %.5f\" % (hits_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'models/transe_model_mar23_variation1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd568e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = restore_model('models/transe_model_mar23_variation1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d187cd",
   "metadata": {},
   "source": [
    "# Variation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f6417",
   "metadata": {},
   "source": [
    "Import the gold standard data (CRIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dbb26b",
   "metadata": {},
   "source": [
    "This is the manually annotated data. I have added the strings for the SCTIDs that were found in the sentences of this dataset. (incorrectly called cuis, they are sctids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d29528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"gold_std_for_kge_cleaned.csv\")\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a3e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"str_for_cui\"] = df2[\"str_for_cui\"].apply(lambda x: preprocess(x)) \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e506d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.rename(columns={\"str_for_cui\": \"subject\"})\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98460e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f8cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['subject'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb88e62",
   "metadata": {},
   "source": [
    "Merge triples from lexicon with pain terms in gold std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a4662",
   "metadata": {},
   "source": [
    "Ref - https://stackoverflow.com/questions/44842458/merging-pandas-columns-one-to-many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df2, df_triples, on='subject', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eab735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3436e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91dc342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples = df[['subject','predicate','object']]\n",
    "df_triples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c8a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples = df_triples.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783faa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('subject has nan: ', df_triples['subject'].isnull().sum())\n",
    "print('predicate has nan: ', df_triples['predicate'].isnull().sum())\n",
    "print('object has nan: ', df_triples['object'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869702c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataframe to list\n",
    "\n",
    "triples = df_triples.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = removeDuplicates(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is type and length\n",
    "\n",
    "print('type is: ', type(triples))\n",
    "print('length is: ', len(triples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecab6e1",
   "metadata": {},
   "source": [
    "Define the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2289eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import train_test_split_no_unseen \n",
    "\n",
    "n = round((len(triples))*0.20) #get 20% of the data as test set\n",
    "\n",
    "X_train, X_valid = train_test_split_no_unseen(np.array(triples), test_size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3bf4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set size: ', X_train.shape)\n",
    "print('Test set size: ', X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c6a312",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924a7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.latent_features import ComplEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac64e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can instantiate the model:\n",
    "\n",
    "model = ComplEx(batches_count=100, \n",
    "                seed=555, \n",
    "                epochs=10, \n",
    "                k=150, \n",
    "                eta=10,\n",
    "                optimizer='adam', \n",
    "                optimizer_params={'lr':1e-3},\n",
    "                loss='multiclass_nll', \n",
    "                regularizer='LP', \n",
    "                regularizer_params={'p':3, 'lambda':1e-5}, \n",
    "                verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a094c",
   "metadata": {},
   "source": [
    "Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13aefe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "model.fit(X_train, early_stopping = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc0fa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the model is fit\n",
    "\n",
    "if model.is_fitted:\n",
    "    print('The model is fit!')\n",
    "else:\n",
    "    print('The model is not fit! Did you skip a step?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31612eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_triples = np.concatenate((X_train, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e1fd54",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b350cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import evaluate_performance\n",
    "\n",
    "ranks = evaluate_performance(X_valid,\n",
    "                             model=model, \n",
    "                             filter_triples=filter_triples,\n",
    "                             use_default_protocol=True,\n",
    "                             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2305af53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import mr_score, mrr_score, hits_at_n_score\n",
    "\n",
    "mrr = mrr_score(ranks)\n",
    "print(\"MRR: %.2f\" % (mrr))\n",
    "\n",
    "hits_10 = hits_at_n_score(ranks, n=10)\n",
    "print(\"Hits@10: %.5f\" % (hits_10))\n",
    "hits_3 = hits_at_n_score(ranks, n=3)\n",
    "print(\"Hits@3: %.5f\" % (hits_3))\n",
    "hits_1 = hits_at_n_score(ranks, n=1)\n",
    "print(\"Hits@1: %.5f\" % (hits_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5dc1be",
   "metadata": {},
   "source": [
    "Saving and restoring a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9743fef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.latent_features import save_model, restore_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1583ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'models/complex_model_mar23_variation2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = restore_model('models/complex_model_mar23_variation2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c762d",
   "metadata": {},
   "source": [
    "Repeat for TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdaa19e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
