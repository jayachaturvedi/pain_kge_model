{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93f040af",
   "metadata": {},
   "source": [
    "# Some notes and references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f8b34",
   "metadata": {},
   "source": [
    "Ampligraph uses a skip gram w2v model for its embeddings\n",
    "(good explanation of skip gram - https://www.kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-skip-gram.html and this - https://towardsdatascience.com/skip-gram-nlp-context-words-prediction-algorithm-5bbf34f84e0c and this - https://towardsdatascience.com/nlp-101-word2vec-skip-gram-and-cbow-93512ee24314)\n",
    "\n",
    "w2v - https://medium.datadriveninvestor.com/word2vec-skip-gram-model-explained-383fa6ddc4ae\n",
    "\n",
    "Ampligraph blog - https://medium.com/featurepreneur/ampligraph-what-is-it-8b243800818c\n",
    "\n",
    "Tutorials from https://github.com/Accenture/AmpliGraph/blob/master/docs/tutorials/AmpliGraphBasicsTutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd270c22",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4944fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version #this script will try it with Ampligraph 2.0.0 so python version is 3.10.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bade81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensorflow.__version__) #should be 1.15 or lower - it is 2.9.0 for apmpligraph v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb53da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ampligraph\n",
    "ampligraph.__version__\n",
    "#should be 2.0.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d6a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185df848",
   "metadata": {},
   "source": [
    "# Import triples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c2f950",
   "metadata": {},
   "source": [
    "These were generated from SNOMED_CT instance on CKG using terms from the pain lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879b992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples = pd.read_csv(\"all_parent_child_for_kge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d37076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3507525",
   "metadata": {},
   "source": [
    "Note: burn seems irrelevant but it has been picked up in order to capture 'burning pain'. It will be of use later on\n",
    "because some of the gold standard annotations (sentences from CRIS) also pick up burn like burn injury or \n",
    "burning things but their label in the classification will be 0 because it is not related to pain\n",
    "so leave it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de7579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples = df_triples.drop(columns='Unnamed: 0')\n",
    "df_triples.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9995ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common text preprocessing\n",
    "text = \"   This is a message to be cleaned. 92. It may involve some things like: *+ {[<br>]}, ?, :, ''  adjacent spaces and tabs     .  \"\n",
    "\n",
    "#convert to lowercase and remove punctuations and characters and then strip\n",
    "def preprocess(text):\n",
    "    text = text.lower() #lowercase text\n",
    "    text=text.strip()  #get rid of leading/trailing whitespace \n",
    "    #text=re.compile('<.*?>').sub('', text) #Remove HTML tags/markups\n",
    "    #text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)  #Replace punctuation with space. Careful since punctuation can sometime be useful\n",
    "    text = re.sub('\\s+', ' ', text)  #Remove extra space and tabs\n",
    "    #text = re.sub(r'\\[[0-9]*\\]',' ',text) #[0-9] matches any digit (0 to 10000...)\n",
    "    text=re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    #text = re.sub(r'\\d',' ',text) #matches any digit from 0 to 100000..., \\D matches non-digits\n",
    "    text = re.sub(r'\\s+',' ',text) #\\s matches any whitespace, \\s+ matches multiple whitespace, \\S matches non-whitespace \n",
    "    \n",
    "    return text\n",
    "\n",
    "text=preprocess(text)\n",
    "print(text)  #text is a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f0891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples[\"subject\"] = df_triples[\"subject\"].apply(lambda x: preprocess(x)) \n",
    "df_triples[\"predicate\"] = df_triples[\"predicate\"].apply(lambda x: preprocess(x)) \n",
    "df_triples[\"object\"] = df_triples[\"object\"].apply(lambda x: preprocess(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3792aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples.describe() #top does not mean the top triple, it is the top for each category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140950b0",
   "metadata": {},
   "source": [
    "# Variation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2658d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the dataframe of triples to a list\n",
    "\n",
    "triples = df_triples.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is type and length\n",
    "\n",
    "print('type is: ', type(triples))\n",
    "print('length is: ', len(triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDuplicates(triples):\n",
    "     \n",
    "    return [t for t in (set(tuple(i) for i in triples))]\n",
    "         \n",
    "\n",
    "triples = removeDuplicates(triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6911c67f",
   "metadata": {},
   "source": [
    "Defining the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcad31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import train_test_split_no_unseen \n",
    "\n",
    "n = round((len(triples))*0.20) #get 20% of the data as test set\n",
    "\n",
    "X_train, X_valid = train_test_split_no_unseen(np.array(triples), test_size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092abb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set size: ', X_train.shape)\n",
    "print('Test set size: ', X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd9b655",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf61f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ampligraph.latent_features import ComplEx # this is for ampligraph 1.4\n",
    "from ampligraph.latent_features import ScoringBasedEmbeddingModel #this is for ampligraph 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e15fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can instantiate the model:\n",
    "\n",
    "''' this is for ampligraph 2.0'''\n",
    "\n",
    "model = ScoringBasedEmbeddingModel(k=150,\n",
    "                                   eta=10,\n",
    "                                   scoring_type='ComplEx',\n",
    "                                   #scoring_type='TransE',\n",
    "                                   seed=555)\n",
    "\n",
    "from ampligraph.latent_features.loss_functions import get as get_loss\n",
    "from ampligraph.latent_features.regularizers import get as get_regularizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-3)\n",
    "loss = get_loss('multiclass_nll') #, {'margin': 5}) #including margin reduces performance\n",
    "regularizer = get_regularizer('LP', {'p': 3, 'lambda': 1e-5})\n",
    "\n",
    "model.compile(loss=loss,\n",
    "              optimizer=optimizer,\n",
    "              entity_relation_regularizer=regularizer,\n",
    "              entity_relation_initializer='glorot_uniform') #including or excluding this did not make a difference on performance\n",
    "\n",
    "''' this is for ampligraph 1.4'''\n",
    "'''\n",
    "model = ComplEx(batches_count=100, \n",
    "                seed=555, \n",
    "                epochs=10, \n",
    "                k=150, \n",
    "                eta=10,\n",
    "                optimizer='adam', \n",
    "                optimizer_params={'lr':1e-3},\n",
    "                loss='multiclass_nll', \n",
    "                regularizer='LP', \n",
    "                regularizer_params={'p':3, 'lambda':1e-5}, \n",
    "                verbose=True) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d6cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "\n",
    "import tensorflow as tf\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "'''this is for ampligraph 2.0'''\n",
    "model.fit(X_train,\n",
    "          batch_size=5000, # this improved performance\n",
    "          epochs=200, #this improved performance\n",
    "          verbose=True)\n",
    "\n",
    "''' this is for ampligraph 1.4'''\n",
    "#model.fit(X_train, early_stopping = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d011c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the model is fit\n",
    "\n",
    "if model.is_fitted:\n",
    "    print('The model is fit!')\n",
    "else:\n",
    "    print('The model is not fit! Did you skip a step?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609874c5",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c294f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are filtered because they are the true triples. negatives ones are the corrput ones generated by the algorithm and are false combinations of triples\n",
    "\n",
    "positives_filter = {'test' : np.concatenate([X_train, X_valid])} # this is for ampligraph 2.0\n",
    "\n",
    "#filter_triples = np.concatenate((X_train, X_valid)) # this is or ampligraph 1.4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f639c",
   "metadata": {},
   "source": [
    "arguments: \n",
    "\n",
    "X - the data to evaluate on. We're going to use our test set to evaluate.\n",
    "\n",
    "model - the model we previously trained.\n",
    "\n",
    "filter_triples - will filter out the false negatives generated by the corruption strategy.\n",
    "\n",
    "use_default_protocol - specifies whether to use the default corruption protocol. If True, then subj and obj are corrupted separately during evaluation.\n",
    "\n",
    "verbose - will give some nice log statements. Let's leave it on for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' this is for ampligraph 2.0'''\n",
    "ranks = model.evaluate(X_valid, \n",
    "                       use_filter=positives_filter,   # Corruption strategy filter defined above \n",
    "                       corrupt_side='s,o', # corrupt subj and obj separately while evaluating\n",
    "                       verbose=True)\n",
    "\n",
    "'''this is for ampligraph 1.4'''\n",
    "'''\n",
    "from ampligraph.evaluation import evaluate_performance\n",
    "\n",
    "ranks = evaluate_performance(X_valid,\n",
    "                             model=model, \n",
    "                             filter_triples=filter_triples,\n",
    "                             use_default_protocol=True,\n",
    "                             verbose=True) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d24037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import mr_score, mrr_score, hits_at_n_score\n",
    "\n",
    "mrr = mrr_score(ranks)\n",
    "print(\"MRR: %.2f\" % (mrr))\n",
    "\n",
    "hits_10 = hits_at_n_score(ranks, n=10)\n",
    "print(\"Hits@10: %.5f\" % (hits_10))\n",
    "hits_3 = hits_at_n_score(ranks, n=3)\n",
    "print(\"Hits@3: %.5f\" % (hits_3))\n",
    "hits_1 = hits_at_n_score(ranks, n=1)\n",
    "print(\"Hits@1: %.5f\" % (hits_1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86a601f-1480-426f-b7b4-7b5663123add",
   "metadata": {},
   "source": [
    "K Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5815203-e7dd-46b1-92fc-51e056e218e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the number of folds for k-fold cross-validation\n",
    "knum = 10  # You can change this value to any desired number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eab705-9418-4a4e-8aab-6ece6c0cf33a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the evaluation results\n",
    "evaluation_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f79d6a-82f3-42af-a377-c3ee59c7407a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a k-fold cross-validator\n",
    "kf = KFold(n_splits=knum, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d78138e-7279-49df-98b4-4342cc4fffb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate through each fold\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(X_train)):\n",
    "    print(f\"Training fold {fold + 1}/{knum}...\")\n",
    "    \n",
    "    # Split the data into training and validation sets for this fold\n",
    "    X_train_fold = X_train[train_index]\n",
    "    X_valid_fold = X_train[valid_index]\n",
    "\n",
    "    \n",
    "    # Define the ComplEx model (here k is embedding size)\n",
    "\n",
    "    model = ScoringBasedEmbeddingModel(k=150, eta=10, scoring_type='ComplEx', seed=555)\n",
    "\n",
    "    # Compile the model before training\n",
    "    model.compile(optimizer=optimizer, loss=loss, entity_relation_regularizer=regularizer, entity_relation_initializer='glorot_uniform')\n",
    "\n",
    "    #model.compile(loss=loss, optimizer='adam', entity_relation_regularizer=regularizer, entity_relation_initializer='glorot_uniform')\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train_fold, batch_size=5000, epochs=200, verbose=True)\n",
    "\n",
    "    positives_filter = {'test' : np.concatenate([X_train_fold, X_valid_fold])}\n",
    "    \n",
    "    # Evaluate the model on the validation data\n",
    "    ranks = model.evaluate(X_valid_fold, use_filter=positives_filter, corrupt_side='s,o', verbose=True)\n",
    "\n",
    "    mrr = np.mean(mrr_score(ranks))\n",
    "    #print(\"MRR: %.2f\" % (mrr))\n",
    "\n",
    "    hits_10 = np.mean(hits_at_n_score(ranks, n=10))\n",
    "    #print(\"Hits@10: %.2f\" % (hits_10))\n",
    "    hits_3 = np.mean(hits_at_n_score(ranks, n=3))\n",
    "    #print(\"Hits@3: %.2f\" % (hits_3))\n",
    "    hits_1 = np.mean(hits_at_n_score(ranks, n=1))\n",
    "    #print(\"Hits@1: %.2f\" % (hits_1))\n",
    "    \n",
    "    # Calculate the Hits@1, Hits@3, and Mean Rank for this fold\n",
    "    #hits_10 = np.mean(ranks[:, 0])\n",
    "    #hits_3 = np.mean(ranks[:, 1])\n",
    "    \n",
    "    # Store the evaluation results for this fold\n",
    "    evaluation_results.append({'Hits@10': hits_10, 'Hits@3': hits_3, 'Hits@1': hits_1, 'mrr': mrr})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8cfd2-2b12-4461-9057-a17442325c60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of the evaluation metrics across all folds\n",
    "hits_1_mean = np.mean([result['Hits@1'] for result in evaluation_results])\n",
    "hits_3_mean = np.mean([result['Hits@3'] for result in evaluation_results])\n",
    "hits_10_mean = np.mean([result['Hits@10'] for result in evaluation_results])\n",
    "mrr_mean = np.mean([result['mrr'] for result in evaluation_results])\n",
    "\n",
    "hits_1_std = np.std([result['Hits@1'] for result in evaluation_results])\n",
    "hits_3_std = np.std([result['Hits@3'] for result in evaluation_results])\n",
    "hits_10_std = np.std([result['Hits@10'] for result in evaluation_results])\n",
    "mrr_std = np.std([result['mrr'] for result in evaluation_results])\n",
    "\n",
    "\n",
    "print(\"\\nMean Evaluation Metrics:\")\n",
    "print(f\"Hits@1: {hits_1_mean} ± {hits_1_std}\")\n",
    "print(f\"Hits@3: {hits_3_mean} ± {hits_3_std}\")\n",
    "print(f\"Hits@10: {hits_10_mean} ± {hits_10_std}\")\n",
    "print(f\"MRR: {mrr_mean} ± {mrr_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081a3ab",
   "metadata": {},
   "source": [
    "Saving and restoring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d6234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ampligraph.latent_features import save_model, restore_model #this is for ampligraph 1.4\n",
    "\n",
    "from ampligraph.utils import save_model, restore_model #this is for amploigraph 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c39e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'models/complex_model_mar23_variation1_kfold.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a4e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = restore_model('models/complex_model_mar23_variation1_kfold.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e1bba",
   "metadata": {},
   "source": [
    "Repeat for TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93a593-f213-406b-968f-de40cb0e231c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Now we can instantiate the model:\n",
    "\n",
    "''' this is for ampligraph 2.0'''\n",
    "\n",
    "model = ScoringBasedEmbeddingModel(k=150,\n",
    "                                   eta=10,\n",
    "                                   #scoring_type='ComplEx',\n",
    "                                   scoring_type='TransE',\n",
    "                                   seed=555)\n",
    "\n",
    "from ampligraph.latent_features.loss_functions import get as get_loss\n",
    "from ampligraph.latent_features.regularizers import get as get_regularizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-3)\n",
    "loss = get_loss('pairwise' , {'margin': 5})\n",
    "regularizer = get_regularizer('LP', {'p': 3, 'lambda': 1e-5})\n",
    "\n",
    "model.compile(loss=loss,\n",
    "              optimizer=optimizer,\n",
    "              entity_relation_regularizer=regularizer,\n",
    "              entity_relation_initializer='glorot_uniform') #including or excluding this did not make a difference on performance\n",
    "\n",
    "''' this is for ampligraph 1.4'''\n",
    "'''\n",
    "model = TransE(batches_count=100, \n",
    "               seed=555, \n",
    "               epochs=10, \n",
    "               k=150, \n",
    "               loss='pairwise',\n",
    "               loss_params={'margin':5},\n",
    "               verbose=True) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0883ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "\n",
    "#import tensorflow as tf\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "\n",
    "'''this is for ampligraph 2.0'''\n",
    "model.fit(X_train,\n",
    "          batch_size=5000, # this improved performance\n",
    "          epochs=200, #this improved performance\n",
    "          verbose=True)\n",
    "\n",
    "''' this is for ampligraph 1.4'''\n",
    "#model.fit(X_train, early_stopping = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d56208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the model is fit\n",
    "\n",
    "if model.is_fitted:\n",
    "    print('The model is fit!')\n",
    "else:\n",
    "    print('The model is not fit! Did you skip a step?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c9ece-80a0-4349-834e-c376a192ba29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positives_filter = {'test' : np.concatenate([X_train, X_valid])} # this is for ampligraph 2.0\n",
    "\n",
    "#filter_triples = np.concatenate((X_train, X_valid)) # this is or ampligraph 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "''' this is for ampligraph 2.0'''\n",
    "ranks = model.evaluate(X_valid, \n",
    "                       use_filter=positives_filter,   # Corruption strategy filter defined above \n",
    "                       corrupt_side='s,o', # corrupt subj and obj separately while evaluating\n",
    "                       verbose=True)\n",
    "\n",
    "'''this is for ampligraph 1.4'''\n",
    "'''\n",
    "from ampligraph.evaluation import evaluate_performance\n",
    "\n",
    "ranks = evaluate_performance(X_valid,\n",
    "                             model=model, \n",
    "                             filter_triples=filter_triples,\n",
    "                             use_default_protocol=True,\n",
    "                             verbose=True) '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200a41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import mr_score, mrr_score, hits_at_n_score\n",
    "\n",
    "mrr = mrr_score(ranks)\n",
    "print(\"MRR: %.2f\" % (mrr))\n",
    "\n",
    "hits_10 = hits_at_n_score(ranks, n=10)\n",
    "print(\"Hits@10: %.5f\" % (hits_10))\n",
    "hits_3 = hits_at_n_score(ranks, n=3)\n",
    "print(\"Hits@3: %.5f\" % (hits_3))\n",
    "hits_1 = hits_at_n_score(ranks, n=1)\n",
    "print(\"Hits@1: %.5f\" % (hits_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd7a01-0f33-43ab-a472-515da874f648",
   "metadata": {},
   "source": [
    "K fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434084ed-9e0b-4020-a9a0-ea296737f211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate through each fold - other parameters were defined above for ComplEx\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(X_train)):\n",
    "    print(f\"Training fold {fold + 1}/{knum}...\")\n",
    "    \n",
    "    # Split the data into training and validation sets for this fold\n",
    "    X_train_fold = X_train[train_index]\n",
    "    X_valid_fold = X_train[valid_index]\n",
    "\n",
    "    \n",
    "    # Define the ComplEx model (here k is embedding size)\n",
    "\n",
    "    model = ScoringBasedEmbeddingModel(k=150, eta=10, scoring_type='TransE', seed=555)\n",
    "\n",
    "    # Compile the model before training\n",
    "    model.compile(optimizer=optimizer, loss=loss, entity_relation_regularizer=regularizer, entity_relation_initializer='glorot_uniform')\n",
    "\n",
    "    #model.compile(loss=loss, optimizer='adam', entity_relation_regularizer=regularizer, entity_relation_initializer='glorot_uniform')\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train_fold, batch_size=5000, epochs=200, verbose=True)\n",
    "\n",
    "    positives_filter = {'test' : np.concatenate([X_train_fold, X_valid_fold])}\n",
    "    \n",
    "    # Evaluate the model on the validation data\n",
    "    ranks = model.evaluate(X_valid_fold, use_filter=positives_filter, corrupt_side='s,o', verbose=True)\n",
    "\n",
    "    mrr = np.mean(mrr_score(ranks))\n",
    "    #print(\"MRR: %.2f\" % (mrr))\n",
    "\n",
    "    hits_10 = np.mean(hits_at_n_score(ranks, n=10))\n",
    "    #print(\"Hits@10: %.2f\" % (hits_10))\n",
    "    hits_3 = np.mean(hits_at_n_score(ranks, n=3))\n",
    "    #print(\"Hits@3: %.2f\" % (hits_3))\n",
    "    hits_1 = np.mean(hits_at_n_score(ranks, n=1))\n",
    "    #print(\"Hits@1: %.2f\" % (hits_1))\n",
    "    \n",
    "    # Calculate the Hits@1, Hits@3, and Mean Rank for this fold\n",
    "    #hits_10 = np.mean(ranks[:, 0])\n",
    "    #hits_3 = np.mean(ranks[:, 1])\n",
    "    \n",
    "    # Store the evaluation results for this fold\n",
    "    evaluation_results.append({'Hits@10': hits_10, 'Hits@3': hits_3, 'Hits@1': hits_1, 'mrr': mrr})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200946b3-ec65-4d41-bd51-da16c6ceef8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of the evaluation metrics across all folds\n",
    "hits_1_mean = np.mean([result['Hits@1'] for result in evaluation_results])\n",
    "hits_3_mean = np.mean([result['Hits@3'] for result in evaluation_results])\n",
    "hits_10_mean = np.mean([result['Hits@10'] for result in evaluation_results])\n",
    "mrr_mean = np.mean([result['mrr'] for result in evaluation_results])\n",
    "\n",
    "hits_1_std = np.std([result['Hits@1'] for result in evaluation_results])\n",
    "hits_3_std = np.std([result['Hits@3'] for result in evaluation_results])\n",
    "hits_10_std = np.std([result['Hits@10'] for result in evaluation_results])\n",
    "mrr_std = np.std([result['mrr'] for result in evaluation_results])\n",
    "\n",
    "\n",
    "print(\"\\nMean Evaluation Metrics:\")\n",
    "print(f\"Hits@1: {hits_1_mean} ± {hits_1_std}\")\n",
    "print(f\"Hits@3: {hits_3_mean} ± {hits_3_std}\")\n",
    "print(f\"Hits@10: {hits_10_mean} ± {hits_10_std}\")\n",
    "print(f\"MRR: {mrr_mean} ± {mrr_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'models/transe_model_mar23_variation1_kfold.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd568e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = restore_model('models/transe_model_mar23_variation1_kfold.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d187cd",
   "metadata": {},
   "source": [
    "# Variation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f6417",
   "metadata": {},
   "source": [
    "Import the gold standard data (CRIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dbb26b",
   "metadata": {},
   "source": [
    "This is the manually annotated data. I have added the strings for the SCTIDs that were found in the sentences of this dataset. (incorrectly called cuis, they are sctids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d29528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"gold_std_for_kge_cleaned.csv\")\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a3e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"str_for_cui\"] = df2[\"str_for_cui\"].apply(lambda x: preprocess(x)) \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e506d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.rename(columns={\"str_for_cui\": \"subject\"})\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98460e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f8cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['subject'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb88e62",
   "metadata": {},
   "source": [
    "Merge triples from lexicon with pain terms in gold std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a4662",
   "metadata": {},
   "source": [
    "Ref - https://stackoverflow.com/questions/44842458/merging-pandas-columns-one-to-many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df2, df_triples, on='subject', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eab735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3436e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91dc342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples = df[['subject','predicate','object']]\n",
    "df_triples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c8a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples = df_triples.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783faa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('subject has nan: ', df_triples['subject'].isnull().sum())\n",
    "print('predicate has nan: ', df_triples['predicate'].isnull().sum())\n",
    "print('object has nan: ', df_triples['object'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869702c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataframe to list\n",
    "\n",
    "triples = df_triples.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = removeDuplicates(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is type and length\n",
    "\n",
    "print('type is: ', type(triples))\n",
    "print('length is: ', len(triples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecab6e1",
   "metadata": {},
   "source": [
    "Define the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2289eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import train_test_split_no_unseen \n",
    "\n",
    "n = round((len(triples))*0.20) #get 20% of the data as test set\n",
    "\n",
    "X_train, X_valid = train_test_split_no_unseen(np.array(triples), test_size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3bf4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train set size: ', X_train.shape)\n",
    "print('Test set size: ', X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c6a312",
   "metadata": {},
   "source": [
    " Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c1fc1-4ddc-47b5-806d-26f46e573980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ampligraph.latent_features import ComplEx # this is for ampligraph 1.4\n",
    "from ampligraph.latent_features import ScoringBasedEmbeddingModel #this is for ampligraph 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc2922-fe61-45fd-b982-1e2ad106b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can instantiate the model:\n",
    "\n",
    "''' this is for ampligraph 2.0'''\n",
    "\n",
    "model = ScoringBasedEmbeddingModel(k=150,\n",
    "                                   eta=10,\n",
    "                                   scoring_type='ComplEx',\n",
    "                                   #scoring_type='TransE',\n",
    "                                   seed=555)\n",
    "\n",
    "from ampligraph.latent_features.loss_functions import get as get_loss\n",
    "from ampligraph.latent_features.regularizers import get as get_regularizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-3)\n",
    "loss = get_loss('multiclass_nll') # , {'margin': 0.5})\n",
    "regularizer = get_regularizer('LP', {'p': 3, 'lambda': 1e-5})\n",
    "\n",
    "model.compile(loss=loss,\n",
    "              optimizer=optimizer,\n",
    "              entity_relation_regularizer=regularizer,\n",
    "              entity_relation_initializer='glorot_uniform') #including or excluding this did not make a difference on performance\n",
    "\n",
    "''' this is for ampligraph 1.4'''\n",
    "'''\n",
    "#Now we can instantiate the model:\n",
    "\n",
    "model = ComplEx(batches_count=100, \n",
    "                seed=555, \n",
    "                epochs=10, \n",
    "                k=150, \n",
    "                eta=10,\n",
    "                optimizer='adam', \n",
    "                optimizer_params={'lr':1e-3},\n",
    "                loss='multiclass_nll', \n",
    "                regularizer='LP', \n",
    "                regularizer_params={'p':3, 'lambda':1e-5}, \n",
    "                verbose=True)\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d2d74-e3c2-4cd7-aea6-7a2742c0f7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "\n",
    "import tensorflow as tf\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "'''this is for ampligraph 2.0'''\n",
    "model.fit(X_train,\n",
    "          batch_size=5000, # this improved performance\n",
    "          epochs=200, #this improved performance\n",
    "          verbose=True)\n",
    "\n",
    "''' this is for ampligraph 1.4'''\n",
    "#model.fit(X_train, early_stopping = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d75ffe-8b79-4caa-a9a3-61c7c3351a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the model is fit\n",
    "\n",
    "if model.is_fitted:\n",
    "    print('The model is fit!')\n",
    "else:\n",
    "    print('The model is not fit! Did you skip a step?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f359613f-5a06-4fdf-a188-8315e980d680",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe46342-e2bf-4544-b62d-f5fdede2245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are filtered because they are the true triples. negatives ones are the corrput ones generated by the algorithm and are false combinations of triples\n",
    "\n",
    "positives_filter = {'test' : np.concatenate([X_train, X_valid])} # this is for ampligraph 2.0\n",
    "\n",
    "#filter_triples = np.concatenate((X_train, X_valid)) # this is or ampligraph 1.4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0263c8a1-61bc-4485-a5be-2d394c1a38a9",
   "metadata": {},
   "source": [
    "arguments: \n",
    "\n",
    "X - the data to evaluate on. We're going to use our test set to evaluate.\n",
    "\n",
    "model - the model we previously trained.\n",
    "\n",
    "filter_triples - will filter out the false negatives generated by the corruption strategy.\n",
    "\n",
    "use_default_protocol - specifies whether to use the default corruption protocol. If True, then subj and obj are corrupted separately during evaluation.\n",
    "\n",
    "verbose - will give some nice log statements. Let's leave it on for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582be7df-590f-4249-93c8-22c311668c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' this is for ampligraph 2.0'''\n",
    "ranks = model.evaluate(X_valid, \n",
    "                       use_filter=positives_filter,   # Corruption strategy filter defined above \n",
    "                       corrupt_side='s,o', # corrupt subj and obj separately while evaluating\n",
    "                       verbose=True)\n",
    "\n",
    "'''this is for ampligraph 1.4'''\n",
    "'''\n",
    "from ampligraph.evaluation import evaluate_performance\n",
    "\n",
    "ranks = evaluate_performance(X_valid,\n",
    "                             model=model, \n",
    "                             filter_triples=filter_triples,\n",
    "                             use_default_protocol=True,\n",
    "                             verbose=True) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a289a-f3ec-49cb-8f16-05d4335a9c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import mr_score, mrr_score, hits_at_n_score\n",
    "\n",
    "mrr = mrr_score(ranks)\n",
    "print(\"MRR: %.2f\" % (mrr))\n",
    "\n",
    "hits_10 = hits_at_n_score(ranks, n=10)\n",
    "print(\"Hits@10: %.5f\" % (hits_10))\n",
    "hits_3 = hits_at_n_score(ranks, n=3)\n",
    "print(\"Hits@3: %.5f\" % (hits_3))\n",
    "hits_1 = hits_at_n_score(ranks, n=1)\n",
    "print(\"Hits@1: %.5f\" % (hits_1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e983aee-82b6-4cd0-b97f-4f843b2744d1",
   "metadata": {},
   "source": [
    "K fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead5c2c6-1502-4ac6-884e-3b78b1a25b8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate through each fold - other parameters were defined above for ComplEx\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(X_train)):\n",
    "    print(f\"Training fold {fold + 1}/{knum}...\")\n",
    "    \n",
    "    # Split the data into training and validation sets for this fold\n",
    "    X_train_fold = X_train[train_index]\n",
    "    X_valid_fold = X_train[valid_index]\n",
    "\n",
    "    \n",
    "    # Define the ComplEx model (here k is embedding size)\n",
    "\n",
    "    model = ScoringBasedEmbeddingModel(k=150, eta=10, scoring_type='ComplEx', seed=555)\n",
    "\n",
    "    # Compile the model before training\n",
    "    model.compile(optimizer=optimizer, loss=loss, entity_relation_regularizer=regularizer, entity_relation_initializer='glorot_uniform')\n",
    "\n",
    "    #model.compile(loss=loss, optimizer='adam', entity_relation_regularizer=regularizer, entity_relation_initializer='glorot_uniform')\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train_fold, batch_size=5000, epochs=200, verbose=True)\n",
    "\n",
    "    positives_filter = {'test' : np.concatenate([X_train_fold, X_valid_fold])}\n",
    "    \n",
    "    # Evaluate the model on the validation data\n",
    "    ranks = model.evaluate(X_valid_fold, use_filter=positives_filter, corrupt_side='s,o', verbose=True)\n",
    "\n",
    "    mrr = np.mean(mrr_score(ranks))\n",
    "    #print(\"MRR: %.2f\" % (mrr))\n",
    "\n",
    "    hits_10 = np.mean(hits_at_n_score(ranks, n=10))\n",
    "    #print(\"Hits@10: %.2f\" % (hits_10))\n",
    "    hits_3 = np.mean(hits_at_n_score(ranks, n=3))\n",
    "    #print(\"Hits@3: %.2f\" % (hits_3))\n",
    "    hits_1 = np.mean(hits_at_n_score(ranks, n=1))\n",
    "    #print(\"Hits@1: %.2f\" % (hits_1))\n",
    "    \n",
    "    # Calculate the Hits@1, Hits@3, and Mean Rank for this fold\n",
    "    #hits_10 = np.mean(ranks[:, 0])\n",
    "    #hits_3 = np.mean(ranks[:, 1])\n",
    "    \n",
    "    # Store the evaluation results for this fold\n",
    "    evaluation_results.append({'Hits@10': hits_10, 'Hits@3': hits_3, 'Hits@1': hits_1, 'mrr': mrr})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff085c-49d1-4479-8c8a-5e4a4632f835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of the evaluation metrics across all folds\n",
    "hits_1_mean = np.mean([result['Hits@1'] for result in evaluation_results])\n",
    "hits_3_mean = np.mean([result['Hits@3'] for result in evaluation_results])\n",
    "hits_10_mean = np.mean([result['Hits@10'] for result in evaluation_results])\n",
    "mrr_mean = np.mean([result['mrr'] for result in evaluation_results])\n",
    "\n",
    "hits_1_std = np.std([result['Hits@1'] for result in evaluation_results])\n",
    "hits_3_std = np.std([result['Hits@3'] for result in evaluation_results])\n",
    "hits_10_std = np.std([result['Hits@10'] for result in evaluation_results])\n",
    "mrr_std = np.std([result['mrr'] for result in evaluation_results])\n",
    "\n",
    "\n",
    "print(\"\\nMean Evaluation Metrics:\")\n",
    "print(f\"Hits@1: {hits_1_mean} ± {hits_1_std}\")\n",
    "print(f\"Hits@3: {hits_3_mean} ± {hits_3_std}\")\n",
    "print(f\"Hits@10: {hits_10_mean} ± {hits_10_std}\")\n",
    "print(f\"MRR: {mrr_mean} ± {mrr_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1583ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'models/complex_model_mar23_variation2_kfold.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = restore_model('models/complex_model_mar23_variation2_kfold.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c762d",
   "metadata": {},
   "source": [
    "Repeat for TransE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0647c1a0-838a-45c5-9045-73659861a596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Now we can instantiate the model:\n",
    "\n",
    "''' this is for ampligraph 2.0'''\n",
    "\n",
    "model = ScoringBasedEmbeddingModel(k=150,\n",
    "                                   eta=10,\n",
    "                                   #scoring_type='ComplEx',\n",
    "                                   scoring_type='TransE',\n",
    "                                   seed=555)\n",
    "\n",
    "from ampligraph.latent_features.loss_functions import get as get_loss\n",
    "from ampligraph.latent_features.regularizers import get as get_regularizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-3)\n",
    "loss = get_loss('pairwise' , {'margin': 5})\n",
    "regularizer = get_regularizer('LP', {'p': 3, 'lambda': 1e-5})\n",
    "\n",
    "model.compile(loss=loss,\n",
    "              optimizer=optimizer,\n",
    "              entity_relation_regularizer=regularizer,\n",
    "              entity_relation_initializer='glorot_uniform') #including or excluding this did not make a difference on performance\n",
    "\n",
    "''' this is for ampligraph 1.4'''\n",
    "'''\n",
    "model = TransE(batches_count=100, \n",
    "               seed=555, \n",
    "               epochs=10, \n",
    "               k=150, \n",
    "               loss='pairwise',\n",
    "               loss_params={'margin':5},\n",
    "               verbose=True) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd540fac-1066-4559-a265-bbb89d14ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "\n",
    "#import tensorflow as tf\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "\n",
    "'''this is for ampligraph 2.0'''\n",
    "model.fit(X_train,\n",
    "          batch_size=5000, # this improved performance\n",
    "          epochs=200, #this improved performance\n",
    "          verbose=True)\n",
    "\n",
    "''' this is for ampligraph 1.4'''\n",
    "#model.fit(X_train, early_stopping = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436b8839-a4ce-4c9e-b3bc-178dfb362749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the model is fit\n",
    "\n",
    "if model.is_fitted:\n",
    "    print('The model is fit!')\n",
    "else:\n",
    "    print('The model is not fit! Did you skip a step?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d028a4c9-7737-49a8-8edc-4d0195a5467f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positives_filter = {'test' : np.concatenate([X_train, X_valid])} # this is for ampligraph 2.0\n",
    "\n",
    "#filter_triples = np.concatenate((X_train, X_valid)) # this is or ampligraph 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63278971-fec0-4827-9aa9-963c30d8ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "''' this is for ampligraph 2.0'''\n",
    "ranks = model.evaluate(X_valid, \n",
    "                       use_filter=positives_filter,   # Corruption strategy filter defined above \n",
    "                       corrupt_side='s,o', # corrupt subj and obj separately while evaluating\n",
    "                       verbose=True)\n",
    "\n",
    "'''this is for ampligraph 1.4'''\n",
    "'''\n",
    "from ampligraph.evaluation import evaluate_performance\n",
    "\n",
    "ranks = evaluate_performance(X_valid,\n",
    "                             model=model, \n",
    "                             filter_triples=filter_triples,\n",
    "                             use_default_protocol=True,\n",
    "                             verbose=True) '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7145a2-18fa-428c-a433-d67b20c1dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampligraph.evaluation import mr_score, mrr_score, hits_at_n_score\n",
    "\n",
    "mrr = mrr_score(ranks)\n",
    "print(\"MRR: %.2f\" % (mrr))\n",
    "\n",
    "hits_10 = hits_at_n_score(ranks, n=10)\n",
    "print(\"Hits@10: %.5f\" % (hits_10))\n",
    "hits_3 = hits_at_n_score(ranks, n=3)\n",
    "print(\"Hits@3: %.5f\" % (hits_3))\n",
    "hits_1 = hits_at_n_score(ranks, n=1)\n",
    "print(\"Hits@1: %.5f\" % (hits_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c75c098-659a-491c-930b-5e55b0f2c645",
   "metadata": {},
   "source": [
    "K fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c14e4-0c8e-4a1b-988a-52372c73732d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate through each fold - other parameters were defined above for ComplEx\n",
    "for fold, (train_index, valid_index) in enumerate(kf.split(X_train)):\n",
    "    print(f\"Training fold {fold + 1}/{knum}...\")\n",
    "    \n",
    "    # Split the data into training and validation sets for this fold\n",
    "    X_train_fold = X_train[train_index]\n",
    "    X_valid_fold = X_train[valid_index]\n",
    "\n",
    "    \n",
    "    # Define the ComplEx model (here k is embedding size)\n",
    "\n",
    "    model = ScoringBasedEmbeddingModel(k=150, eta=10, scoring_type='TransE', seed=555)\n",
    "\n",
    "    # Compile the model before training\n",
    "    model.compile(optimizer=optimizer, loss=loss, entity_relation_regularizer=regularizer, entity_relation_initializer='glorot_uniform')\n",
    "\n",
    "    #model.compile(loss=loss, optimizer='adam', entity_relation_regularizer=regularizer, entity_relation_initializer='glorot_uniform')\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train_fold, batch_size=5000, epochs=200, verbose=True)\n",
    "\n",
    "    positives_filter = {'test' : np.concatenate([X_train_fold, X_valid_fold])}\n",
    "    \n",
    "    # Evaluate the model on the validation data\n",
    "    ranks = model.evaluate(X_valid_fold, use_filter=positives_filter, corrupt_side='s,o', verbose=True)\n",
    "\n",
    "    mrr = np.mean(mrr_score(ranks))\n",
    "    #print(\"MRR: %.2f\" % (mrr))\n",
    "\n",
    "    hits_10 = np.mean(hits_at_n_score(ranks, n=10))\n",
    "    #print(\"Hits@10: %.2f\" % (hits_10))\n",
    "    hits_3 = np.mean(hits_at_n_score(ranks, n=3))\n",
    "    #print(\"Hits@3: %.2f\" % (hits_3))\n",
    "    hits_1 = np.mean(hits_at_n_score(ranks, n=1))\n",
    "    #print(\"Hits@1: %.2f\" % (hits_1))\n",
    "    \n",
    "    # Calculate the Hits@1, Hits@3, and Mean Rank for this fold\n",
    "    #hits_10 = np.mean(ranks[:, 0])\n",
    "    #hits_3 = np.mean(ranks[:, 1])\n",
    "    \n",
    "    # Store the evaluation results for this fold\n",
    "    evaluation_results.append({'Hits@10': hits_10, 'Hits@3': hits_3, 'Hits@1': hits_1, 'mrr': mrr})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c834b1c4-7809-482d-b9db-07b1134d05cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of the evaluation metrics across all folds\n",
    "hits_1_mean = np.mean([result['Hits@1'] for result in evaluation_results])\n",
    "hits_3_mean = np.mean([result['Hits@3'] for result in evaluation_results])\n",
    "hits_10_mean = np.mean([result['Hits@10'] for result in evaluation_results])\n",
    "mrr_mean = np.mean([result['mrr'] for result in evaluation_results])\n",
    "\n",
    "hits_1_std = np.std([result['Hits@1'] for result in evaluation_results])\n",
    "hits_3_std = np.std([result['Hits@3'] for result in evaluation_results])\n",
    "hits_10_std = np.std([result['Hits@10'] for result in evaluation_results])\n",
    "mrr_std = np.std([result['mrr'] for result in evaluation_results])\n",
    "\n",
    "\n",
    "print(\"\\nMean Evaluation Metrics:\")\n",
    "print(f\"Hits@1: {hits_1_mean} ± {hits_1_std}\")\n",
    "print(f\"Hits@3: {hits_3_mean} ± {hits_3_std}\")\n",
    "print(f\"Hits@10: {hits_10_mean} ± {hits_10_std}\")\n",
    "print(f\"MRR: {mrr_mean} ± {mrr_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b001a48a-02d5-4f03-9c4d-4376b2e8024a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
